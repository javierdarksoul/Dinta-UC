{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f7539cd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Javier Rojas Herrera**\n",
    "\n",
    "jrojash1995@gmail.com\n",
    "\n",
    "**Hardware, Deployment y MLOps**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1899cc5e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Letra pequeña del Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfe39d6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Entrenamiento e Inferencia requieren de hardware avanzado en computo numérico**\n",
    "* Se requieren grandes volumenes de datos etiquetados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67507df",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "###  <center>[<img src=\"images/gpuvscpuvstpu.webp\" width=\"80%\"/> ](attachment:image.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4482dfa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## GPU (graphics processing unit)\n",
    "###  <center>[<img src=\"images/A100.jpg\" width=\"60%\"/> ](attachment:image.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d09b6d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## GPU vs CPU\n",
    "###  <center>[<img src=\"images/gpuvscpu.png\" width=\"60%\"/> ](attachment:image.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3257d301",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## GPU vs CPU: Inferencia\n",
    "###  <center>[<img src=\"images/gpuvscpu2.png\" width=\"70%\"/> ](attachment:image.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aeabb6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Tabla resumen GPUS\n",
    "\n",
    "|GPU |  Cuda cores | Tensor cores | VRAM  | Power | Precio |\n",
    "|----------|----------|----------| ----------|  ----------| ----------|\n",
    "| T4    | 2500   | 320  | 15 GB | 70 W | 1100 usd |\n",
    "| L4   | 7680   | 240  | 24 GB | 72 W | 2600 usd |\n",
    "| L40   | 18176    | 568  | 48 GB | 300 W | 8400 usd |\n",
    "| A100    | 6920   |  422   | 80 GB | 400 W | 12000 usd |\n",
    "| H100    | 14592    |  456    | 80 GB | 350 W | 30000 usd |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b52118b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Dec 21 15:42:07 2023       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 545.29.06              Driver Version: 545.29.06    CUDA Version: 12.3     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce RTX 3080        Off | 00000000:07:00.0 Off |                  N/A |\r\n",
      "|  0%   44C    P8              23W / 320W |    224MiB / 10240MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|    0   N/A  N/A       592      G   /usr/lib/Xorg                               116MiB |\r\n",
      "|    0   N/A  N/A       618      G   /usr/bin/sddm-greeter                        94MiB |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21bd084e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from torchvision.models import vit_b_16 , ViT_B_16_Weights\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader,Subset\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from trans import UnNormalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eca1658a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "##load model VIT B 16\n",
    "weights = ViT_B_16_Weights.DEFAULT\n",
    "preprocess = weights.transforms()\n",
    "model = vit_b_16(weights=weights)\n",
    "model.heads.head = torch.nn.Linear(768,10)\n",
    "\n",
    "##set optimizer and loss\n",
    "optim = torch.optim.Adam(model.parameters())\n",
    "cross_entropy = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "##load data into dataloader\n",
    "data = CIFAR10(\"./\", download=True, train=True, transform=weights.transforms())\n",
    "data = CIFAR10(\"./\", download=True, train=True, transform=weights.transforms())\n",
    "subset_indices = torch.randperm(len(data))[:1000]\n",
    "subset_cifar10 = Subset(data, subset_indices)\n",
    "dataloader = DataLoader(subset_cifar10, batch_size=32, shuffle=False)\n",
    "\n",
    "class_names = [\"Airplane\",\"Auto\",\"Bird\",\"Cat\",\"Deer\",\"Dog\",\"Frog\",\"Horse\",\"Ship\",\"Truck\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e678e0e8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66228c701b1548afa0cdc8b0237901ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1000, description='x', max=3000, min=-1000), Output()), _dom_classes=('w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "std = weights.transforms().std\n",
    "mean = weights.transforms().mean\n",
    "invTrans=UnNormalize(mean,std)\n",
    "@interact\n",
    "def show_articles_more_than(x=1000):\n",
    "    plt.figure(figsize=(5,3))\n",
    "    print(\"Label: \",class_names[data[x][1]])\n",
    "    plt.axis('off')\n",
    "    plt.imshow(invTrans(data[x][0]).permute(1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579dd92b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ¿Qué elementos utilizan VRAM en un entrenamiento?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f5823b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "---\n",
    "\n",
    "- Almacenamiento de tensores de entrada\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ee0a99",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Almacenamiento de los parametros del modelo (weight and biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72653ada",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Almacenamiento de gradientes (backpropagation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b94faf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Almacenamiento de tensores de salida\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97997fe5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Dec 21 15:46:42 2023       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 545.29.06              Driver Version: 545.29.06    CUDA Version: 12.3     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce RTX 3080        Off | 00000000:07:00.0 Off |                  N/A |\r\n",
      "|  0%   45C    P2              24W / 320W |    463MiB / 10240MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|    0   N/A  N/A       592      G   /usr/lib/Xorg                               116MiB |\r\n",
      "|    0   N/A  N/A       618      G   /usr/bin/sddm-greeter                        94MiB |\r\n",
      "|    0   N/A  N/A     10005      C   ...avier/miniconda3/envs/UC/bin/python      234MiB |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "## Tomando un batch del dataloader y transfiriendolo a VRAM\n",
    "for image,label in dataloader:\n",
    "    image_=image.cuda()\n",
    "    break\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4f16c44",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Dec 21 15:47:20 2023       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 545.29.06              Driver Version: 545.29.06    CUDA Version: 12.3     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce RTX 3080        Off | 00000000:07:00.0 Off |                  N/A |\r\n",
      "|  0%   47C    P2              23W / 320W |    845MiB / 10240MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|    0   N/A  N/A       592      G   /usr/lib/Xorg                               116MiB |\r\n",
      "|    0   N/A  N/A       618      G   /usr/bin/sddm-greeter                        94MiB |\r\n",
      "|    0   N/A  N/A     10005      C   ...avier/miniconda3/envs/UC/bin/python      616MiB |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "## transfiriendo el modelo a VRAM\n",
    "model = model.cuda()\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68624d74",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Locura de los parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b56a87",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "# <center>[ <img src=\"images/madness.png\" width=\"60%\"/>](attachment:image.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e5cb8b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ¿Cómo aprovechar al maximo el hardware disponible?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e24b88d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# FP32 vs FP16\n",
    "\n",
    " # <center>[ <img src=\"images/fp16.ppm\" width=\"80%\"/>](attachment:image.png)</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566541da",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ¿Es posible usar representacion de FP16 para entrenar?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a11b96c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Algunas operaciones como las convoluciones o lineales, pueden realizarse completamente en FP16\n",
    "* Sin embargo, otras operaciones como la reducción, a menudo pueden necesitar la representacion en FP32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9286ea29",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Precision mixta (AMP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e86bbc2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " # <center>[ <img src=\"images/amp.png\"/>](attachment:image.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8051a32c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " # Tensor cores\n",
    " \n",
    " # <center>[ <img src=\"images/tensor_cores.gif\"/>](attachment:image.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd59c861",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " # <center>[ <img src=\"images/tensorop.png\" width=100%/>](attachment:image.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa854b6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Entrenamiento tradicional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6951616",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo por epoca: 10.426695585250854 segs | Epoch loss: 79.35196542739868\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    time_i=time.time()\n",
    "    epoch_loss = 0.0\n",
    "    for image,label in dataloader:\n",
    "        optim.zero_grad() \n",
    "        image=image.cuda()  \n",
    "        label=label.cuda()\n",
    "        output = model(image)   \n",
    "        loss= cross_entropy(output,label)        \n",
    "        loss.backward()     \n",
    "        epoch_loss+=loss.item()\n",
    "        optim.step()\n",
    "    print(f'Tiempo por epoca: {time.time()-time_i} segs | Epoch loss: {epoch_loss}')        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45594eb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Entrenamiento utilizando precision mixta + tensor cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "019b7b52",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo por epoca: 4.730200529098511 segs | Epoch loss: 72.21149444580078\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    time_i=time.time()\n",
    "    epoch_loss = 0.0\n",
    "    for image,label in dataloader:\n",
    "        optim.zero_grad()\n",
    "        image=image.cuda()\n",
    "        label=label.cuda()\n",
    "        with torch.autocast(device_type=\"cuda\"):\n",
    "            output = model(image)\n",
    "            loss= cross_entropy(output,label)        \n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        epoch_loss+=loss.item()\n",
    "    print(f'Tiempo por epoca: {time.time()-time_i} segs | Epoch loss: {epoch_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb53aca1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ¿Qué problemas pueden ocurrir al trabajar con una precisión de 16 bits?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3044f1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Cálculo de gradientes acumulativos podrian no poder representarse en FP16 (Desvanecimiento de gradiente)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518c0f47",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Entrenamiento con cálculo de gradiente escalado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64e45378",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo por epoca: 4.647127866744995 segs | Epoch loss: 67.93331909179688\n",
      "Tiempo por epoca: 4.6152918338775635 segs | Epoch loss: 66.21737670898438\n",
      "Tiempo por epoca: 4.61234712600708 segs | Epoch loss: 65.7242431640625\n"
     ]
    }
   ],
   "source": [
    "scaler = torch.cuda.amp.GradScaler()  \n",
    "for epoch in range(3):\n",
    "    time_i=time.time()\n",
    "    epoch_loss = 0.0\n",
    "    for image,label in dataloader:\n",
    "        optim.zero_grad()\n",
    "        image=image.cuda()\n",
    "        label=label.cuda()\n",
    "        with torch.autocast(device_type=\"cuda\"):\n",
    "            output = model(image)\n",
    "            loss= cross_entropy(output,label)        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optim)\n",
    "        scaler.update()\n",
    "        epoch_loss+=loss.item()\n",
    "    print(f'Tiempo por epoca: {time.time()-time_i} segs | Epoch loss: {epoch_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f796dae",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ¿Qué sucede si no dispongo de hardware o si requiero de pocas horas de computo?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5dbaf0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Principales servicios cloud para creación de máquinas virtuales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c4d260",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# <center>[<img src=\"images/azurevs.jpg\" width=\"80%\"/>](attachment:image.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556f1db6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Pros de utilizar máquinas virtuales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443bac77",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Fácil de crear y configurar según las necesidades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed82860",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Costo bajo al corto plazo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90af5fb3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Integración directa con otros servicios cloud del mismo prestador"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ff4a71",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Contras de utilizar máquinas virtuales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a26bb3d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Los recursos solicitados pueden no estar disponibles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea883953",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Alto costo a largo plazo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e800d0a5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ¿Usar MV es lo más eficiente para realizar tareas de machine learning en la nube?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57e8cab",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Los modelos en MV no escalan (Inferencia)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50885492",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Entrenamiento y despliegue de modelos complejo de automatizar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584bf193",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# <center>[<img src=\"images/mlstudiovsvertex.png\" width=\"60%\"/>](attachment:image.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a5f460",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Ventajas al utilizar servicios especializados para ML en la nube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a4a203",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Deployment escalable y automatizado de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb53cd95",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Entrenamiento automatizado (pipelines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e54a4e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Disponibilidad de una familia de modelos pre entrenados a través de API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbff1ad0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Creación de notebooks jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a780998e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center>[<img src=\"images/mlsteps.jpg\" width=\"80%\"/>](attachment:image.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f9a375",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Deployment de modelos de ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589d3e22",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Disponibilizar modelos para el uso real de usuarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907bce5b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# <center>[<img src=\"images/depl.png\" width=\"50%\"/>](attachment:image.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f558970d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Modelo como API\n",
    "# <center>[<img src=\"images/apimodel.png\" width=\"70%\"/>](attachment:image.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990925b4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Frameworks para deployment de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fae36b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# <center>[<img src=\"images/deploy.png\" width=\"70%\"/>](attachment:image.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843cbdb0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Ejemplo:  Bento ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eed7ec10",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(tag=\"vit16:owiia2vahcjejnbo\", path=\"/home/javier/bentoml/models/vit16/owiia2vahcjejnbo/\")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bentoml\n",
    "bentoml.pytorch.save_model(\n",
    "    \"vit16\",   # Model name\n",
    "    model,  # objeto que contiene al modelo\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f91ac16",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Modelo como API\n",
    "# <center>[<img src=\"images/depl2.png\" width=\"70%\"/>](attachment:image.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea64de65",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problemas de levantar modelos API en MV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1569ccc3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# <center>[<img src=\"images/apin2.png\" width=\"70%\"/>](attachment:image.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26666bbc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solución: Escalar modelos API en cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06a05be",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# <center>[<img src=\"images/depl4.png\" width=\"50%\"/>](attachment:image.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37a3418",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "### Mostrar ejemplo de escalamiento en VERTEX AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e57909a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ¿Qué es MLOps?\n",
    "\n",
    "* Paradigma repetible que tiene como objetivo implementar y mantener modelos de aprendizaje automático en producción de manera confiable y eficiente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4c1c58",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# <center>[<img src=\"images/mlops.png\" width=\"80%\"/>](attachment:image.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed8c019",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pipelines en MLOps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6f9a7a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Una Pipeline es un flujo de trabajo conformado por uno o varios componentes y sus interacciones a través de entradas y salidas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e372ddd",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# <center>[<img src=\"images/compo.png\" width=\"60%\"/>](attachment:image.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fe6a7b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# <center>[<img src=\"images/pipeline.png\" width=\"60%\"/>](attachment:image.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7385ce",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Frameworks para MLOps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a6b4e4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# <center>[<img src=\"images/mlops_frame2.png\" width=\"70%\"/>](attachment:image.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353d1c2d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Servicios cloud para MLOps\n",
    "# <center>[<img src=\"images/mlstudiovsvertex.png\" width=\"60%\"/>](attachment:image.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5822f7ea",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ejemplo de pipeline de juguete definida en Kubeflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffdf042a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10005/299293933.py:2: DeprecationWarning: The module `kfp.v2` is deprecated and will be removed in a futureversion. Please import directly from the `kfp` namespace, instead of `kfp.v2`.\n",
      "  from kfp.v2 import compiler\n",
      "/run/media/javier/miniconda3/envs/UC/lib/python3.10/site-packages/kfp/dsl/component_decorator.py:119: FutureWarning: Python 3.7 has reached end-of-life. The default base_image used by the @dsl.component decorator will switch from 'python:3.7' to 'python:3.8' on April 23, 2024. To ensure your existing components work with versions of the KFP SDK released after that date, you should provide an explicit base_image argument and ensure your component works as intended on Python 3.8.\n",
      "  return component_factory.create_component_from_func(\n"
     ]
    }
   ],
   "source": [
    "import kfp.dsl as dsl\n",
    "from kfp.v2 import compiler\n",
    "\n",
    "@dsl.component\n",
    "def add(a: float, b: float) -> float:\n",
    "    return a + b\n",
    "\n",
    "@dsl.component\n",
    "def mul(a: float, b: float) -> float:\n",
    "    return a * b\n",
    "\n",
    "@dsl.pipeline\n",
    "def add_pipeline(a: float, b: float):\n",
    "    add_task = add(a=a, b=b)\n",
    "    mul_task = mul(a=a, b=add_task.output)\n",
    "    \n",
    "compiler.Compiler().compile(pipeline_func=add_pipeline, package_path='add_pipeline.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8189434e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ejemplo de Pipeline real en vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56ac8f8",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# <center>[<img src=\"images/vertex.png\" width=\"56%\"/>](attachment:image.png)</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e643f2b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
